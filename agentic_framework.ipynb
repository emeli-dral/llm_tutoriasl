{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b4dc43-a642-4416-abad-3a5fd9e17ce6",
   "metadata": {},
   "source": [
    "# Agents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642c990-a3ce-4440-8b89-927e82589bde",
   "metadata": {},
   "source": [
    "## Response framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78023b40-db19-40f3-b59e-56827753981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from agents import Agent, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f28bc06-929a-4a69-ae7c-6b3ed4464688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like there are a couple of small issues in your code snippet. Here's a corrected version:\n",
      "\n",
      "```python\n",
      "total = 0  # 'totak' should be 'total'\n",
      "for i in range(10):\n",
      "    total += i**2\n",
      "```\n",
      "\n",
      "Now, let's break down what this code does:\n",
      "\n",
      "1. It initializes a variable `total` to 0.\n",
      "2. It then iterates over a range of numbers from 0 to 9 (inclusive), where `range(10)` generates numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9.\n",
      "3. The square of each number (`i**2`) is added to `total`.\n",
      "\n",
      "To find the output, we can calculate the sum of squares from 0 to 9:\n",
      "\n",
      "- **0**Â² = 0\n",
      "- **1**Â² = 1\n",
      "- **2**Â² = 4\n",
      "- **3**Â² = 9\n",
      "- **4**Â² = 16\n",
      "- **5**Â² = 25\n",
      "- **6**Â² = 36\n",
      "- **7**Â² = 49\n",
      "- **8**Â² = 64\n",
      "- **9**Â² = 81\n",
      "\n",
      "Now, summing these values:\n",
      "\n",
      "0 + 1 + 4 + 9 + 16 + 25 + 36 + 49 + 64 + 81 = 285\n",
      "\n",
      "Therefore, the final output stored in `total` after this code runs would be **285**.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"What will be the output of my python function total = 0; for i in range(10): total += i**2\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32f742-ac54-47de-8051-ab029993aef9",
   "metadata": {},
   "source": [
    "## Agentic framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528b3db-45db-43be-be07-15fbc9ac67cd",
   "metadata": {},
   "source": [
    "Agents - is a new framework, built on top of basic responses/completion API. \n",
    "\n",
    "Agentic framework introduces few abstractions to build agentic AI apps more efficient:\n",
    "* Agent  -  LLMs equipped with instructions and tools\n",
    "* Handoffs - a way to coordinate and delegate between multiple agents\n",
    "* Guardrails - Â input validations in parallel to agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cb64536-f7df-49f2-9a25-f3efcb6c6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8754e955-9578-428a-8a02-cdaeb4603e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/ipaddress.py:45: RuntimeWarning: coroutine 'Runner.run' was never awaited\n",
      "  return IPv4Address(address)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down your Python code step by step:\n",
      "\n",
      "```python\n",
      "total = 0\n",
      "for i in range(10):\n",
      "    total += i**2\n",
      "```\n",
      "\n",
      "You're initializing `total` to 0, then looping `i` from **0 to 9** (since `range(10)` is 0 up to, but not including, 10) and at each iteration, adding \\(i^2\\) to `total`.\n",
      "\n",
      "Let's compute the values:\n",
      "\n",
      "- When i = 0: total += 0^2 â†’ total = 0\n",
      "- When i = 1: total += 1^2 â†’ total = 1\n",
      "- When i = 2: total += 4   â†’ total = 5\n",
      "- When i = 3: total += 9   â†’ total = 14\n",
      "- When i = 4: total += 16  â†’ total = 30\n",
      "- When i = 5: total += 25  â†’ total = 55\n",
      "- When i = 6: total += 36  â†’ total = 91\n",
      "- When i = 7: total += 49  â†’ total = 140\n",
      "- When i = 8: total += 64  â†’ total = 204\n",
      "- When i = 9: total += 81  â†’ total = 285\n",
      "\n",
      "**So, the final output (i.e., the value of `total`) is:**\n",
      "\n",
      "```\n",
      "285\n",
      "```\n",
      "\n",
      "You can confirm this by running:\n",
      "\n",
      "```python\n",
      "total = 0\n",
      "for i in range(10):\n",
      "    total += i**2\n",
      "print(total)\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "```\n",
      "285\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=\"gpt-4.1\")\n",
    "\n",
    "result = await Runner.run(agent, \"What will be the output of my python function total = 0; for i in range(10): total += i**2\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692fbf7-c267-49a0-ae27-43de1ad34914",
   "metadata": {},
   "source": [
    "The runner then runs a loop:\n",
    "1. We call the LLM for the current agent, with the current input.\n",
    "2. The LLM produces its output.\n",
    "    * If the LLM returns aÂ final_output, the loop ends and we return the result.\n",
    "    * If the LLM does a handoff, we update the current agent and input, and re-run the loop.\n",
    "    * If the LLM produces tool calls, we run those tool calls, append the results, and re-run the loop.\n",
    "3. If we exceed the max_turns passes, we raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbeafdf4-59f7-43eb-a672-e433b0c28949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#this should fail\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat will be the output of my python function total = 0; for i in range(10): total += i**2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mfinal_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/site-packages/agents/run.py:335\u001b[0m, in \u001b[0;36mRunner.run_sync\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_sync\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     previous_response_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunResult:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run a workflow synchronously, starting at the given agent. Note that this just wraps the\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m    `run` method, so it will not work if there's already an event loop (e.g. inside an async\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    function, or in a Jupyter notebook or async context like FastAPI). For those cases, use\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstarting_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_turns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/asyncio/base_events.py:629\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    632\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py11/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "#this should fail\n",
    "result = Runner.run_sync(agent, \"What will be the output of my python function total = 0; for i in range(10): total += i**2\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7365c-5e48-4f6c-b6b8-97a0b99d5735",
   "metadata": {},
   "source": [
    "In **Jupyter notebooks**, always use **await Runner.run(...)** instead of run_sync(...). \n",
    "\n",
    "Jupyter already runs an event loop, and trying to start another will cause errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f5c11-e120-46bd-8c37-7f9379ea3caa",
   "metadata": {},
   "source": [
    "## Hosted tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0f3a172-4e08-4737-93d4-a05f0e847712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, WebSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a888c4e4-617c-47f0-8618-8995f061e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    tools=[\n",
    "        WebSearchTool(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76ba54ee-e368-4073-ba7e-7065abe7e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I donâ€™t have real-time data access, so I canâ€™t provide the current weather in London right now. For the latest weather updates, please check a reliable source such as:\n",
      "\n",
      "- [BBC Weather - London](https://www.bbc.co.uk/weather/2643743)\n",
      "- [Met Office - London](https://www.metoffice.gov.uk/weather/forecast/gcpvj0v07)\n",
      "- [Weather.com - London](https://weather.com/weather/today/l/London+United+Kingdom)\n",
      "\n",
      "If you have enabled a weather app or assistant (like Google Assistant or Siri), you can also ask: â€œWhatâ€™s the weather in London today?â€ for instant results!\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(agent, \"What the weather in London is like today?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ef48262-24a7-46a1-abcd-79a48d4235bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 1:30 PM on Wednesday, April 16, 2025, in London, the weather is partly sunny with a temperature of 60Â°F (16Â°C).\n",
      "\n",
      "## Weather for London, Greater London, United Kingdom:\n",
      "Current Conditions: Partly sunny, 60Â°F (16Â°C)\n",
      "\n",
      "Daily Forecast:\n",
      "* Wednesday, April 16: Low: 42Â°F (6Â°C), High: 61Â°F (16Â°C), Description: Windy with some clouds, then sunshine\n",
      "* Thursday, April 17: Low: 46Â°F (8Â°C), High: 64Â°F (18Â°C), Description: Partly sunny\n",
      "* Friday, April 18: Low: 49Â°F (9Â°C), High: 64Â°F (18Â°C), Description: Pleasant with clouds and sunshine\n",
      "* Saturday, April 19: Low: 45Â°F (7Â°C), High: 60Â°F (16Â°C), Description: Cloudy\n",
      "* Sunday, April 20: Low: 47Â°F (8Â°C), High: 61Â°F (16Â°C), Description: Low clouds\n",
      "* Monday, April 21: Low: 49Â°F (9Â°C), High: 60Â°F (16Â°C), Description: Cloudy with a couple of showers in the afternoon\n",
      "* Tuesday, April 22: Low: 48Â°F (9Â°C), High: 63Â°F (17Â°C), Description: Partial sunshine with a couple of showers, mainly early in the day\n",
      "\n",
      "\n",
      "Please note that weather conditions can change, so it's advisable to check for the latest updates if you have plans outdoors. \n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(search_agent, \"What the weather in London is like today?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f05f4b-fce2-442e-96e2-599d8ba2cba6",
   "metadata": {},
   "source": [
    "more on buildin tools: https://openai.github.io/openai-agents-python/tools/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47c497-340e-487a-b1d0-d13b91c1f94f",
   "metadata": {},
   "source": [
    "## Function tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf5c6975-ada9-4ba1-8a5f-4278b3a6f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import TypedDict, Any\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "837f0ac7-696e-4702-8070-2a24533e214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(TypedDict):\n",
    "    lat: float\n",
    "    long: float\n",
    "\n",
    "@function_tool  \n",
    "async def fetch_weather(location: Location) -> str:\n",
    "    \"\"\"Fetch the weather for a given location.\n",
    "\n",
    "    Args:\n",
    "        location: The location to fetch the weather for.\n",
    "    \"\"\"\n",
    "    # In real life, we'd fetch the weather from a weather API\n",
    "    return \"sunny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0223d469-af5d-4ff6-b966-9c186d11c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_a_tool = Agent(\n",
    "    name=\"Assistant with tools\",\n",
    "    tools=[fetch_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c95a8c5-9495-4c69-843e-f8b97b9c35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given Python function will calculate the sum of the squares of the numbers from 0 to 9. Here's the breakdown of what it does:\n",
      "\n",
      "1. Initializes `total` to 0.\n",
      "2. Iterates over each integer `i` from 0 to 9.\n",
      "3. For each `i`, it adds `i**2` (i squared) to `total`.\n",
      "\n",
      "Here's the process step-by-step:\n",
      "\n",
      "- When `i = 0`: total += 0\\*\\*2 = 0\n",
      "- When `i = 1`: total += 1\\*\\*2 = 1\n",
      "- When `i = 2`: total += 2\\*\\*2 = 4\n",
      "- When `i = 3`: total += 3\\*\\*2 = 9\n",
      "- When `i = 4`: total += 4\\*\\*2 = 16\n",
      "- When `i = 5`: total += 5\\*\\*2 = 25\n",
      "- When `i = 6`: total += 6\\*\\*2 = 36\n",
      "- When `i = 7`: total += 7\\*\\*2 = 49\n",
      "- When `i = 8`: total += 8\\*\\*2 = 64\n",
      "- When `i = 9`: total += 9\\*\\*2 = 81\n",
      "\n",
      "Adding up these values:\n",
      "\n",
      "0 + 1 + 4 + 9 + 16 + 25 + 36 + 49 + 64 + 81 = 285\n",
      "\n",
      "So, the output of the function will be `total = 285`.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(agent_with_a_tool, \"What will be the output of my python function total = 0; for i in range(10): total += i**2\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dde9d2c-8ba7-491d-8b95-1c775b866bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to real-time data, including current weather updates. For the most accurate and up-to-date weather in London today, please check a reliable weather website like [BBC Weather](https://www.bbc.co.uk/weather), [Weather.com](https://weather.com), or a weather app on your smartphone.\n",
      "\n",
      "If you tell me what youâ€™re planning to do, I can give you general advice on Londonâ€™s typical weather for this time of year!\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(agent, \"What the weather in London is like today?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab59b37-1291-47a1-a58e-cad764b3fca1",
   "metadata": {},
   "source": [
    "result = await Runner.run(agent_with_a_tool, \"What the weather in London is like today?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc572c-3a0d-4a81-b584-877cca68f660",
   "metadata": {},
   "source": [
    "## Agent as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1c667d0-144c-4f5f-9867-921f9d0bdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd6a1eaa-f84f-43ca-b846-5937e63fa724",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_agent = Agent(\n",
    "    name=\"Russian agent\",\n",
    "    instructions=\"You translate the user's message to Russian\",\n",
    ")\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"French agent\",\n",
    "    instructions=\"You translate the user's message to French\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d3dd151-a8b9-4016-b356-d7a9ea12f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        russian_agent.as_tool(\n",
    "            tool_name=\"translate_to_russian\",\n",
    "            tool_description=\"Translate the user's message to Spanish\",\n",
    "        ),\n",
    "        french_agent.as_tool(\n",
    "            tool_name=\"translate_to_french\",\n",
    "            tool_description=\"Translate the user's message to French\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9669869-117c-49e6-8805-60587defc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello, how are you?\" in Thai is \"à¸ªà¸§à¸±à¸ªà¸”à¸µ à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¸šà¹‰à¸²à¸‡?\"\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Thai.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd86644a-7d77-4337-b10d-7e23f78632c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(output=[ResponseOutputMessage(id='msg_67ffabc71ac88192ad95843edfba8e27061d3a88aa36cb1d', content=[ResponseOutputText(annotations=[], text='\"Hello, how are you?\" in Thai is \"à¸ªà¸§à¸±à¸ªà¸”à¸µ à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¸šà¹‰à¸²à¸‡?\"', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=125, output_tokens=24, total_tokens=149), response_id='resp_67ffabc64ea0819294f4745c1ee037fa061d3a88aa36cb1d')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in result.raw_responses:\n",
    "    print(step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da2d1f8c-4bb7-4376-a181-3efd0212f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello, how are you?\" in French is: \"Bonjour, comment Ã§a va ?\"\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in French.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7eb23ac8-8637-462f-a257-fbc40561d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Hello, how are you?\"}', call_id='call_PqabFSFmzKoI5O0LmQbjEp31', name='translate_to_french', type='function_call', id='fc_67ffabe23c408192b703099f1cfdfdbc0d52e9dde6ef70ca', status='completed')], usage=Usage(requests=1, input_tokens=125, output_tokens=22, total_tokens=147), response_id='resp_67ffabe1b1d481929ca2a51866d6629d0d52e9dde6ef70ca')\n",
      "\n",
      "\n",
      "ModelResponse(output=[ResponseOutputMessage(id='msg_67ffabe42edc8192a768a69207b23e640d52e9dde6ef70ca', content=[ResponseOutputText(annotations=[], text='\"Hello, how are you?\" in French is: \"Bonjour, comment Ã§a va ?\"', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=163, output_tokens=20, total_tokens=183), response_id='resp_67ffabe3b43081929cf41dc8757565940d52e9dde6ef70ca')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in result.raw_responses:\n",
    "    print(step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea047c00-1197-4e2d-82fc-77868d084f8c",
   "metadata": {},
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in French and in Russian.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d99cd9f5-984c-4c21-a69b-e2a2597293f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"Hello, how are you?\"}', call_id='call_rZGu4hM3boo8KAfsr67NZJdE', name='translate_to_french', type='function_call', id='fc_67ffabf5f7908192a9e297428ac01c3c0642b864a2d3e916', status='completed'), ResponseFunctionToolCall(arguments='{\"input\":\"Hello, how are you?\"}', call_id='call_jNyXrxSpzsSMI2wmVIJCZUWL', name='translate_to_russian', type='function_call', id='fc_67ffabf63294819298cc8184fcc421050642b864a2d3e916', status='completed')], usage=Usage(requests=1, input_tokens=0, output_tokens=0, total_tokens=0), response_id='resp_67ffabf4f2c08192abd9dfe1dc633f4c0642b864a2d3e916')\n",
      "\n",
      "\n",
      "ModelResponse(output=[ResponseOutputMessage(id='msg_67ffabf856f88192b3d2bf62105813160642b864a2d3e916', content=[ResponseOutputText(annotations=[], text='In French: \"Bonjour, comment Ã§a va ?\"\\n\\nIn Russian: \"ÐŸÑ€Ð¸Ð²ÐµÑ‚, ÐºÐ°Ðº Ñ‚Ñ‹?\"', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=198, output_tokens=23, total_tokens=221), response_id='resp_67ffabf7b3cc8192970391c3b59995100642b864a2d3e916')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in result.raw_responses:\n",
    "    print(step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483797f-6fcc-4e43-8aec-bb3ff726931e",
   "metadata": {},
   "source": [
    "more on function calls: https://openai.github.io/openai-agents-python/tools/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290a4bd-05e6-4bf5-8fb7-44a989a95d48",
   "metadata": {},
   "source": [
    "## Handoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abaa602-43ff-49c7-a86b-4252b9181f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d48a639d-f4f2-490f-b0ae-311bfe77a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tutor_agent = Agent(\n",
    "    name=\"History Tutor\",\n",
    "    handoff_description=\"Specialist agent for historical questions\",\n",
    "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
    ")\n",
    "\n",
    "math_tutor_agent = Agent(\n",
    "    name=\"Math Tutor\",\n",
    "    handoff_description=\"Specialist agent for math questions\",\n",
    "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c98a353d-bffe-496f-a86f-04436f61d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=\"You determine which agent to use based on the user's question\",\n",
    "    handoffs=[history_tutor_agent, math_tutor_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc3c4ec4-bbcb-40ac-813d-e62b40c6f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Maya civilization was a Mesoamerican culture that existed in present-day Mexico, Guatemala, Belize, Honduras, and El Salvador. It is renowned for its advanced writing system, art, architecture, and mathematical and astronomical systems. Hereâ€™s a brief overview of what happened to the Maya civilization:\n",
      "\n",
      "### Classic Period (c. 250â€“900 AD)\n",
      "- **Flourishing City-States**: During this time, the Maya civilization reached its peak with the development of numerous city-states, each with its own ruler. Major cities included Tikal, CopÃ¡n, Palenque, and Calakmul.\n",
      "- **Cultural Achievements**: They made significant advances in mathematics, astronomy, and writing with the development of the Maya script.\n",
      "- **Architecture and Art**: The Maya built impressive stone structures, pyramids, palaces, and observatories.\n",
      "\n",
      "### Collapse of the Classic Period\n",
      "- **Environmental Factors**: Deforestation and drought likely contributed to the decline of many city-states.\n",
      "- **Political Conflicts**: Increased warfare and competition between city-states destabilized the political structure.\n",
      "- **Socio-Economic Issues**: Overpopulation, resource depletion, and internal social upheaval may have also played roles.\n",
      "\n",
      "### Post-Classic Period (c. 900â€“1500 AD)\n",
      "- **Northern Expansion**: The civilizationâ€™s focus shifted north to the YucatÃ¡n Peninsula with cities like Chichen Itza and Uxmal gaining prominence.\n",
      "- **Continued Decline**: Despite some resurgence, the power of the Maya eventually waned.\n",
      "\n",
      "### Spanish Conquest (16th Century)\n",
      "- **Colonization and Destruction**: The Spanish arrived in the 16th century and conquered the region. Much of Maya culture, including books and records, was destroyed.\n",
      "  \n",
      "### Legacy\n",
      "- **Cultural Influence**: Despite the decline of their city-states, the Maya people survived, and their descendants still live in Central America today, preserving aspects of their culture and languages.\n",
      "- **Ongoing Discoveries**: Archaeological discoveries continue to shed light on the ancient civilization, offering insights into their sophisticated society.\n",
      "\n",
      "The decline of the Maya civilization was not a single event, but rather a gradual process influenced by a combination of environmental, social, and political factors.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(triage_agent, \"What has happened to Maya civilization?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea728384-6ef8-4529-880c-9057bb06e010",
   "metadata": {},
   "source": [
    "### A short note on Agent as a tool vs Handoffs \n",
    "\n",
    "ðŸ”§ **Agent as Tool**\n",
    "* One agent calls another like a function.\n",
    "* The calling agent stays in control.\n",
    "* The tool agent just returns data or output, like a tool or utility.\n",
    "\n",
    "Analogy: You ask a calculator to compute something and you use the result.\n",
    "\n",
    "Use Agent as Tool when:\n",
    "* You need to stay in control of the logic.\n",
    "* The sub-agentâ€™s output is just data to be used.\n",
    "* You want deterministic, synchronous behavior.\n",
    "\n",
    "ðŸ¤ **Handoff Between Agents**\n",
    "\n",
    "What it means:\n",
    "* One agent passes the control flow to another agent entirely.\n",
    "* The second agent takes over, continues the conversation or task.\n",
    "* The first agent steps out and doesnâ€™t return until (maybe) the second agent finishes.\n",
    "\n",
    "Analogy: You go to a therapits, and they hand you off to a specialist who now handles your care.\n",
    "\n",
    "Use Handoff when:\n",
    "* The receiving agent needs to fully take over a task.\n",
    "* You want modular, autonomous agent behavior.\n",
    "* The system is meant to be open-ended or conversational."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30162c25-ba1d-4236-8b50-394055c4c774",
   "metadata": {},
   "source": [
    "## Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9843acf-d53a-4752-ad24-6ff584223039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    TResponseInputItem,\n",
    "    input_guardrail,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf6207ce-3a13-4b5b-9ee6-19bdafcc7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationOutput(BaseModel):\n",
    "    is_translation: bool\n",
    "    reasoning: str\n",
    "\n",
    "guardrail_agent = Agent( \n",
    "    name=\"Guardrail check\",\n",
    "    instructions=\"Check if the user is asking you to translate something.\",\n",
    "    output_type=TranslationOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2f5732e-a7ba-4907-bad1-cbcdb169174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@input_guardrail\n",
    "async def translation_guardrail(ctx: RunContextWrapper[None], \n",
    "                                agent: Agent, input: str | list[TResponseInputItem]) -> GuardrailFunctionOutput:\n",
    "    \n",
    "    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=result.final_output, \n",
    "        tripwire_triggered= not result.final_output.is_translation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ffb6d47d-cded-4bfd-8881-e62e80d17358",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_agent = Agent(  \n",
    "    name=\"Translation angent\",\n",
    "    instructions=\"You are a translation agent. You help users to translate text to different languages\",\n",
    "    input_guardrails=[translation_guardrail],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4ce9389-9f3d-40f1-a405-ecf9f9e542ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation guardrail tripped\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = await Runner.run(translation_agent, \"Hello, can you help me to write some python code?\")\n",
    "    print(\"Guardrail didn't trip - this is unexpected\")\n",
    "    print(\"\\n\")\n",
    "    print(result.final_output)\n",
    "    \n",
    "except InputGuardrailTripwireTriggered:\n",
    "    print(\"Translation guardrail tripped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30ab782e-4d32-47c0-9627-1a5d7af83466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardrail didn't trip - this is fine\n",
      "\n",
      "\n",
      "In Thai, you can say \"à¹„à¸¡à¹ˆà¹€à¸­à¸²à¸„à¸£à¸±à¸š à¸‚à¸­à¸šà¸„à¸¸à¸“à¸„à¸£à¸±à¸š\" for males or \"à¹„à¸¡à¹ˆà¹€à¸­à¸²à¸„à¹ˆà¸° à¸‚à¸­à¸šà¸„à¸¸à¸“à¸„à¹ˆà¸°\" for females.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = await Runner.run(translation_agent, \"Hello, how do I say 'No, thank you' in Thai?\")\n",
    "    print(\"Guardrail didn't trip - this is fine\")\n",
    "    print(\"\\n\")\n",
    "    print(result.final_output)\n",
    "    \n",
    "except InputGuardrailTripwireTriggered:\n",
    "    print(\"Translation guardrail tripped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f73201-dbf5-49bd-9fea-1e244a98f3d1",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37844c63-f7d9-4bb0-a20d-a5592ba6c959",
   "metadata": {},
   "source": [
    "An LLM only sees whatâ€™s in the conversation history. To give it new data, you can:\n",
    "* Add it to the Agent instructions (static or dynamic).\n",
    "* Include it in the input passed to Runner.run(...).\n",
    "* Provide it through function tools the LLM can call on demand.\n",
    "* Use retrieval or web search tools to fetch data when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f31fcf6-b907-4128-b074-006f48e38447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from agents import Agent, Runner, RunContextWrapper, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a047d7d-c0af-4f8f-a3e5-2b24800b8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "async def summarize_last_user_question(ctx: RunContextWrapper[None]) -> str:\n",
    "    history = ctx.context.get(\"chat_history\", [])\n",
    "    last_user_msg = next(\n",
    "        (msg[\"content\"] for msg in reversed(history) if msg.get(\"role\") == \"user\"),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if last_user_msg:\n",
    "        return f\"You previously asked: '{last_user_msg[:100]}...'\"\n",
    "    else:\n",
    "        return \"I couldn't find any previous user messages.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "725303f4-0cc5-4b03-aad1-eea4d2b629ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tool_agent = Agent(\n",
    "    name=\"History-aware Assistant\",\n",
    "    instructions=\"You help users reflect on their recent questions using chat history.\",\n",
    "    tools=[summarize_last_user_question],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ad75ad1b-61a9-4cc6-9c35-179598bcbd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: History content received by tool: [{'role': 'user', 'content': 'How do I write a SQL query to join two tables?'}, {'role': 'assistant', 'content': 'Would you like an inner join or outer join?'}, {'role': 'user', 'content': 'I think I need a left join.'}]\n",
      "Earlier, you asked about needing a left join. Let me know if there's anything else you'd like to know!\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"user\", \"content\": \"How do I write a SQL query to join two tables?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Would you like an inner join or outer join?\"},\n",
    "    {\"role\": \"user\", \"content\": \"I think I need a left join.\"}\n",
    "]\n",
    "\n",
    "result = await Runner.run(\n",
    "    history_tool_agent,\n",
    "    input=\"Can you summarize what I asked earlier?\",\n",
    "    context={\"chat_history\": chat_history}\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
